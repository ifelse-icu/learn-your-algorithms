# 02 \| 时间复杂度

写程序，是一门艺术，算法需要用程序实现，而衡量一个程序写的好不好，维度有很多：

* 比如说它的复用性可扩展性

但是从执行层面，去思考一个程序（一个算法），我们更关心它的**正确性**以及以及这段程序执行的**性能**也就是**时间开销**，称为时间复杂度；还有它的**内存占用**，也就的**空间开销，**称为空间复杂度。

我们先学度量算法的方法，再学算法。对于新手，理解时间复杂度的意义更大，新人完全会在这里打开一扇门，给自己所有写的程序找到一个新的理论依据。今天，我们就先从时间复杂度入手学习。后续林䭽再给大家安排空间复杂度的课程。

## 为什么会有时间复杂度？

衡量一段程序的执行速度是一件非常复杂的事情。

首先你不可用绝对的时间去衡量。同样的程序在不同的机器上，执行效率是不一样的：比如CPU好的机器来执行，速度自然就快。



![](.gitbook/assets/image%20%281%29.png)

然后不可以用模糊的「快」「慢」来衡量。比如说有的程序，当输入规模比较小的时候，可以正常的快速的返回结果。但当输入规模超过某一个临界点的时候，这个程序，就永远都跑不完了。这就好比一个10平方米的迷宫，游客走出来很容易；但如果造一个10平方公里的迷宫，游客就很难走出来了。 

最后，执行时间是不稳定的，同样的程序，相同的环境，执行两次的时间也是不一样的。这是机器内部的环境是相对复杂的，没有完全一样的两个时刻。

那么如何去衡量一段程序的执行速度呢？如何创造一种衡量标准能够抛开复杂的外因，仅仅思考程序本身的快慢呢？

于是聪明的科学家们，想到了用「执行时间和规模增长的增长关系」，去看一个程序的执行效率。而这个关系，就是**时间复杂度**。

#### O\(1\)时间

有没有这样一段程序，它的执行时间不随输入规模的增长而增长呢？

当然有，比如定义一个变量，或者从数组中取出第99项。这个时候，定义时间复杂度是 `O(1)` 。

如果我们把时间记为 `T` ，那么我们可以表示为**T~O\(1\)**。

![](.gitbook/assets/image%20%282%29.png)

#### O\(n\)时间

下面这个函数程序，是一个for循环，它的作用是从1加到n。

```javascript
// Javascript
function sum(n){
  let r = 0
  for(let i = 1; i <= n; i++){
    r+=i
  } 
  return r
}
sum(100)
```

```java
// Java
int sum(int n){
    var r = 0;
    for(var i = 1; i <= n; i++) {
        r+=i;
    }

    return r;
}
```

```go
// GO
func sum(n int) int {
	r := 0
	for i := 1; i <= n; i++ {
		r += i
	}
	return r
}
```

```python
# Python
def sum(n):
  r=0
  for i in range(1, n+1):
    r+=i
  return r

```

上面的函数就是一个算法，在这个算法中 `n` 是输入规模。对于这样一个循环，输入规模每增加1，这个for循环就需要多进行一次， `r` 也需要多累加一次， `i` 也需要多自增一次。像这种，输入规模每增加1，执行次数增加在一个常数范围内的，我们说这个算法的时间复杂度是 `O(n)` 。记为**T~O\(n\)**。

![](.gitbook/assets/image%20%283%29.png)

#### O\(m\*n\)时间

下面这段程序，我们初始化一个n乘以n的二维数组。





### Javascript版

```javascript
// Javascript
function init(A, n, value) {
  for(let i = 0; i < n; i ++) {
    A[i] = []
    for(let j = 0; j < n; j++){
      A[i][j] = value
    }
  }
}
```

外层循环需要要执行n次，内存循环，也要执行n次，这样一共，就执行了n×n次。因此，输入每增加1，执行次数就从 `nxn` 增加到 `(n+1)(n+1)` 。想这样的关系，我们称为时间复杂度是O\(n^2\)。记为**T~O\(n^2\)**。

这种关系我们可以推广到一般情况，如果是初始化一个 `mxn` 的二维数组，那么时间复杂度是**T~O\(m\*n\)**。

如果初始化一个 `mxnxp` 的三维数组，时间复杂度是**T~O\(m\*n\*p\)**。

以此类推，如果初始化一个每个维度长度都是 `n` 的100维数组，时间复杂度是**T~O\(n^100\)**。



### Java版

```java
// Java
void init(Integer[][] A, int n, int value) {
    for(int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            A[i][j] = value;
        }
    }
}

```

外层循环需要要执行n次，内存循环，也要执行n次，这样一共，就执行了n×n次。因此，输入每增加1，执行次数就从 `nxn` 增加到 `(n+1)(n+1)` 。想这样的关系，我们称为时间复杂度是O\(n^2\)。记为**T~O\(n^2\)**。

这种关系我们可以推广到一般情况，如果是初始化一个 `mxn` 的二维数组，那么时间复杂度是**T~O\(m\*n\)**。

如果初始化一个 `mxnxp` 的三维数组，时间复杂度是**T~O\(m\*n\*p\)**。

以此类推，如果初始化一个每个维度长度都是 `n` 的100维数组，时间复杂度是**T~O\(n^100\)**。

### Go版

```go
// Go
// go的数组是值类型, slice才是引用类型
// 我们这里用slice替代数组
func initArray(A [][]int, n int, value int) {
	for i := 0; i < n; i++ {
		A[i] = make([]int, n)
		for j := 0; j < n; j++ {
			A[i][j] = value
		}
	}
}
```

外层循环需要要执行n次，内存循环，也要执行n次，这样一共，就执行了n×n次。因此，输入每增加1，执行次数就从 `nxn` 增加到 `(n+1)(n+1)` 。想这样的关系，我们称为时间复杂度是O\(n^2\)。记为**T~O\(n^2\)**。

这种关系我们可以推广到一般情况，如果是初始化一个 `mxn` 的二维数组，那么时间复杂度是**T~O\(m\*n\)**。

如果初始化一个 `mxnxp` 的三维数组，时间复杂度是**T~O\(m\*n\*p\)**。

以此类推，如果初始化一个每个维度长度都是 `n` 的100维数组，时间复杂度是**T~O\(n^100\)**。



```python
# Python
def initArray(A, n, value):
  A = [[]] * n
  for i in range(n):
    A[i] = [value] * n
```





**举例练习:思考下面这个程序的时间复杂度。**

```javascript
function pairs(str) {
  const p = []
  for(let i = 0; i < str.length; i++) {
    for(let j = i; j < str.length; j++) {
      p.push(str[i] + "," + str[j])
    }
  }
  return p
}


// pairs("ABCD")
// 返回： 
// ["A,A", "A,B", "A,C", "A,D", "B,B", "B,C", "B,D", "C,C", "C,D", "D,D"]
```

上面这种情况不是非常的规则，主要是内层循环不是稳定的次数，因此，我们需要去数具体的执行次数。

经过一番观察，可以发现外层循执行了n次。但是内层循环的次数，是由n到1递减。

这时候，我们就需要利用一些初中数学知识去求这个时间复杂度。比如我们可以这样思考：

\#绘图示意

| 第x次外层循环执行 | 1 | 2 | 3 | …… | n-1 | n |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 内层循环执行次数 | n | n-1 | n-2 | …… | 2 | 1 |

通过首尾对应位置两两相加可知：

序号1+序号n : n+1次

序号2+序号n-1: n+1次

序号3+序号n-2: n+1次

……

通过上面的方法收尾相加，内层循环执行的总次数是：

T=\(n+1\)\*n/2 = n^2/2 + n/2

大家现在可以思考一个问题：上面这种情况的时间复杂度是多少？ 上面的计算是不是应该看做一个O\(n^2/2\)的算法和一个O\(n/2\)算法的加和呢？

另外，我们先思考一个更简单的问题，O\(n/2\)和O\(n\)的区别是什么？

我们研究算法复杂度，目的就是希望可以忽略常数因子的影响，具体的原因我们之前提到过，常数因子不影响增长规律；另一方面，如果我们太在意常数因子，我们的算法就必须研究到每一个指令占用了多少时间，这样对大家分析程序执行也会带来非常大的心智负担。所以，这里不如简化模型，认为O\(n/2\)还是O\(n\)。这是一类问题，就是给定输入规模每增加1，执行需要的时间增加一个常数的算法问题。

同理，那么O\(n^2/2\)也就是O\(n^2\)的问题。

多提一个问题O\(n^2/1000\)和O\(1000n^2\)也是O\(n^2\)的问题吗？

是的，虽然一个常数很大另一个常数很小，但是从时间复杂度上来看，我们简化模型，认为他们都是一样的增长规律，就是O\(n^2\)。

最后，那上面的算法是不是一个O\(n^2\) +O\(n\)的问题呢？

因为，O\(n^2\)增长比O\(n\)快太多。 比如n=100是，n^2=1W。因此我们分析算法可以考虑忽略增长慢的部分，注意算法关注的是数据关系，而非具体的数值。因此O\(n^2\) + O\(n\) = O\(n\)。

总结一下，时间复杂度分析思考的是增长趋势，随着规模增长哪个因素在算法中占有主导地位，哪个因素就是时间复杂度重点考虑的因素，其他因素就可以忽略。

#### O\(logn\)时间

接下来我们看一个有趣一点的例子，假如我们有这样的一个函数，它的输入规模是1M（1024\*1024\)。其内部是一个递归的迭代。每进行一次迭代，就可以忽略掉一半的规模。如下面这个函数。函数本身没有意义，主要是用来帮助大家理解时间复杂度。

我们想知道这个函数的时间复杂度是多少？

```text
function foo(n){
  if(n == 1) {return 1}
  return foo(n/2)
}
foo(1024*1024)
```

我们来思考这个问题，第1次递归后，输入规模变成了512k；第2次递归后，规模变成256k；然后是128k; 然后是64k……直到规模为1。

从1M到1总共有多少次计算呢？其实这是一个指数运算的逆运算，你要看2的多少次方是1M。其实就是20次。

所以上面这样的算法，时间复杂度是O\(log\_2\(n\)\)，因为我们不太关心常数，有时直接记为O\(logn\)。相当于指数运算的逆运算，是一个对数运算。这种时间复杂度的算法执行效率是非常高的。比如规模是10亿条数据\(1G左右），也只需要不到30次计算。

#### O\(2^n\)时间

和对数运算相反的，就是指数运算，如果有这样一个算法，输入规模为n的时候，算法会被拆分成两个n-1规模的子问题。如下面函数：

```text
function bar(n){
  if(n == 1) { return 1 }
  return bar(n-1) + bar(n-1)
}
```

第一级递归，会产生两个子问题。每个子问题，会产生另外的两个子问题。因此第2级递归，就是4个子问题。然后是8个子问题。最后一级递归，就是2^\(n-1\)个规模为1的问题。

像这样的算法，时间复杂度是多少呢？

因为我们最终看到了2^\(n-1\)个规模为1的子问题，因此我们认为这个算法的复杂度至少是O\(2^n\)级别的。事实上，这个算法复杂度也是O\(2^n\)。而且分析到一个算法是O\(2^n\)，我们就不必再多思考了。因为这个算法不可行！为什么呢？

在我们历史上有一个著名的摩尔定律说：人类的计算能力，每18~24个月就会翻倍。大家思考下，我们人类的计算能力18~24个月才翻倍，而这个算法规模增加1，时间开销就翻倍了。因此，这类算法是不可行的。

总结下，就是当我们遇到一个算法，其中一部分因素算出来是O\(2^n\)这种级别，我们就可以不去考虑它了。 因为已经不重要了，这是我们人类算法无解的问题。我们必须用其他算法替代，或者优化这个算法。

我这里如此给大家分析，是希望大家省略掉复杂的数学证明过程，因为认知才是最重要的。

#### 什么算法可以使用？

通常的O\(n\)、O\(logn\)、O\(n^2\)的算法是我们通常意义单机就可以解决的。O\(n^2\)的算法在需要满足实时性的时候，如果规模较大，略微慢一点，但是可以接受。比如规模过10W后，O\(n^2\)的算法用时会变得很恐怖。但是对于10W规模的输入，O\(logn\)的算法可以轻松执行完成。O\(n\)的算法会消耗大量CPU资源，但基本可以为用户保证实时性。因为我们现在的CPU可以每秒计算亿次。 另外在O\(n\)和O\(n^2\)之间，还存在一种中间的级别的复杂度，就是O\(nlogn\)，这种级别复杂度也是可以基本保证实时性要求的。

超过O\(n^2\)的算法，比如O\(n^3\), O\(n^4\) …… O\(n^100\)，只要没有到O\(2^n\)级别，我们通常认为是可以被解决的。至少，还没有超越人类算力的进步速度。但是超过O\(n^2\)的算法，通常就不建议实时解决。比如说可以考虑离线计算，比如用大数据集群，或者显卡，用几千个核心并发计算。如果是好的显卡，O\(n^3\)、O\(n^4\)的计算且数据规模不大，也可以实时。

O\(n!\)和O\(2^n\)的算法，我们认为是不可解决的问题，通常不去使用。

#### 复杂度的加法和乘法

上文已经提到过，通常复杂度相加，取影响最大的复杂度

例如：

1. O\(n^2\) + O\(n\) = O\(n^2\)
2. O\(n^3\) + O\(n^2\) = O\(n^3\)

大家可以思考下O\(2^n\) + O\(n^1000000\)算法的复杂度是多少？

虽然n小于某个数值前，都是O\(n^1000000\)耗时大，但是到达某个值后，O\(2^n\)会反超，而且会增长越来越快。因为最终还是O\(2^n\)增长块，所以这是一个O\(2^n\)的算法。

另外如果O\(n\) + O\(n\) = O\(n\)。常数级别不影响数量，但是n个O\(n\)相加是O\(n^2\)，这相当于O\(n\)\*O\(n\)=O\(n^2\)。

#### 总结

这节课我们讨论了算法的时间复杂度。 我们用复杂度来衡量算法的执行时间，是为找到算法的本质因素——就是算法设计的好坏。以后大家会看到各种各样的算法，我们都需要用到今天的方法去思考复杂度。

好的，这节课就到这里，下一节课，我们将学习第一个数据结构——数组。 再见！

